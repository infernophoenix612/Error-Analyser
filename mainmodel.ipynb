{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from random import randint as ri , shuffle \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pd.read_csv('C:/Users/nvarshney014/OneDrive - PwC/Desktop/Project/Data/output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features = ['volt','rotate','pressure','vibration']\n",
    "output_data[features] = scaler.fit_transform(output_data[features])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "output_data['failure'] = label_encoder.fit_transform(output_data['failure'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(output_data,seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    machine_ids = output_data['machineID'].unique()\n",
    "    for mid in machine_ids:\n",
    "        machine_data=output_data[output_data['machineID']==mid]\n",
    "        for i in range(len(machine_data)-seq_length):\n",
    "            seq = machine_data.iloc[i:i+seq_length][features].values\n",
    "            label = machine_data.iloc[i+seq_length]['failure']\n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "seq_length=2\n",
    "X,y = create_sequences(output_data,seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(len(X))\n",
    "X = X[shuffled_indices]\n",
    "y = y[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0],-1)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], seq_length, len(features))\n",
    "\n",
    "print(X_train_resampled.shape)\n",
    "print(y_train_resampled.shape)\n",
    "\n",
    "X_train_resampled, X_val, y_train_resampled, y_val = train_test_split(X_train_resampled, y_train_resampled, test_size=0.2, random_state=42, stratify=y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(units=20, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),  # First LSTM layer\n",
    "    LSTM(units=20, activation='relu',return_sequences=True),  # Second LSTM layer with return_sequences=True\n",
    "    Dropout(0.5),\n",
    "    LSTM(units=20, activation='relu'),\n",
    "    Dense(units=20, activation='relu'),\n",
    "    Dense(units=5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "# dropout ko 0.5\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1, min_delta=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "class_weights_dict = {i:class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=5, batch_size=64, validation_data=(X_val, y_val), class_weight=class_weights_dict, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions_proba = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_labelled = np.argmax(predictions_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy on test data: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "rep = classification_report(y_test , predictions_labelled)\n",
    "conf= confusion_matrix(y_test, predictions_labelled)\n",
    "\n",
    "print(rep)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training set class distribution:\", np.bincount(y_train_resampled))\n",
    "print(\"validation set class distribution:\", np.bincount(y_val))\n",
    "print(\"test set class distribution:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"historyexp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "model.save(\"historyexp.keras\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
